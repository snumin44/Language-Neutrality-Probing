#  ðŸŠ Probing Language Neutrality of Multilingual Representations
> __Title : Revisiting the Language Neutrality of Pre-trained Multilingual Representations through Contrastive Learning__ 

## 1. Introduction 
- __Language Neutrality__, which is often called language agnostic nature, has been treated as a core concept in the field of multilingual PLMs. Since the pre-trained multilingual representations is projected â€‹â€‹into the unified vector space regardless of its language, it can represent universal meaning if the representations do not include characteristics of each language.
- 

## 2. Method

## 3. Experiment

## 4. Conclusions
